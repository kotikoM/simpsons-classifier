{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Inference\n",
    "\n",
    "This notebook loads the trained CNN model from `train.ipynb` and uses it to generate predictions for a folder of unseen images.\n",
    "\n",
    "All predictions are stored in a results.json file with the format:"
   ],
   "id": "50f22fceb4af3a8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n"
   ],
   "id": "44068650e62695ba"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-09T17:09:35.291331Z",
     "start_time": "2025-12-09T17:09:35.264083800Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Must match the size used during training\n",
    "pic_size = 64\n",
    "\n",
    "# These must be identical to the training notebook\n",
    "# If you saved them in a file, import them:\n",
    "# from training_notebook_variables import class_names, idx_to_class\n",
    "# Otherwise define manually:\n",
    "\n",
    "class_names = sorted([\n",
    "    d for d in os.listdir(\"./data/simpsons/archive/characters_train\")\n",
    "    if os.path.isdir(os.path.join(\"./data/simpsons/archive/characters_train\", d))\n",
    "])\n",
    "\n",
    "class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
    "idx_to_class = {i: name for name, i in class_to_idx.items()}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Image Processing",
   "id": "5637927e2d5edc7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:10:01.104374800Z",
     "start_time": "2025-12-09T17:10:01.065182800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    \"\"\"\n",
    "    Load an image using OpenCV, convert to RGB, resize, normalize,\n",
    "    and convert into a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (pic_size, pic_size))\n",
    "\n",
    "    tensor = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "    return tensor.unsqueeze(0)  # Add batch dimension"
   ],
   "id": "ce47d4d94d730ec8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference Function",
   "id": "fb2ffb0d247c0d69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:11:46.455871600Z",
     "start_time": "2025-12-09T17:11:46.424027800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from model import CNN4Conv\n",
    "\n",
    "def infer(data_dir, model_path):\n",
    "    \"\"\"\n",
    "    Load the trained model and perform inference on all images inside data_dir.\n",
    "    Creates a results.json file mapping filename â†’ predicted class.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load model\n",
    "    model = CNN4Conv(num_classes=len(class_names))\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for filename in sorted(os.listdir(data_dir)):\n",
    "        full_path = os.path.join(data_dir, filename)\n",
    "\n",
    "        if not os.path.isfile(full_path):\n",
    "            continue\n",
    "\n",
    "        img_tensor = load_and_preprocess_image(full_path)\n",
    "        if img_tensor is None:\n",
    "            print(f\"Skipping invalid image: {filename}\")\n",
    "            continue\n",
    "\n",
    "        img_tensor = img_tensor.to(device)\n",
    "\n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            logits = model(img_tensor)\n",
    "            pred_idx = logits.argmax(1).item()\n",
    "            pred_name = idx_to_class[pred_idx]\n",
    "\n",
    "        results[filename] = pred_name\n",
    "\n",
    "    # Save results\n",
    "    with open(\"results.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(f\"Saved results.json with {len(results)} predictions.\")"
   ],
   "id": "95e660edb89b2761",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run Inference",
   "id": "7d58e0be454982e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:14:27.240316700Z",
     "start_time": "2025-12-09T17:14:13.323192600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = \"./data/simpsons/archive/characters_train/abraham_grampa_simpson\" # change this\n",
    "model_path = \"simpsons_cnn4conv.pth\"\n",
    "\n",
    "infer(data_dir, model_path)"
   ],
   "id": "7404dc0c49c8a964",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results.json with 731 predictions.\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
